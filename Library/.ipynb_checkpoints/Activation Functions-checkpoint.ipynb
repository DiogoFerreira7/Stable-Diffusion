{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"Module.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Test both np.maximum vs .min_clamp\n",
    "        return np.maximum(0, inputs)\n",
    "    \n",
    "    def bwd(self, output, inputs):\n",
    "        # The gradient of a ReLU is either:\n",
    "        # 1 - if value > 0\n",
    "        # 0 - if value <= 0\n",
    "        # Using pytorch tensor() inputs > 0 will create a boolean array\n",
    "        # which you can convert to float (true / false -> 1.0 / 0.0)\n",
    "        inputs.g = 2 * (inputs > 0).float() - out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d208c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
